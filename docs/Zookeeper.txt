Zookeeper

================================================================================
Zookeeper实战之单机模式

Zookeeper介绍
Zookeeper 分布式服务框架是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。本文主要从使用者角度来介绍一下Zookeeper的安装，配置及应用。

单机安装
Zookeeper可以单机安装，这种应用模式主要用在测试或demo的情况下，在生产环境下一般不会采用。
1. 首先可以从Zookeeper的官方网站下载最新的安装包http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz
2. 解压zookeeper到指定目录下，这里假定为/opt/zookeeper
3. 进入zookeeper目录下的conf目录，复制zoo_sample.cfg为zoo.cfg，并将内容修改如下

tickTime=2000
dataDir=/opt/zookeeper-3.4.6/data
clientPort=2181

tickTime：Zookeeper 服务器之间或客户端与服务器之间心跳的时间间隔。
dataDir：Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。
clientPort：Zookeeper 服务器监听端口，用来接受客户端的访问请求。

4. 配置完以后，就可以启动zookeeper服务了，进入Zookeeper/bin目录，运行下面的命令来启动Zookeeper服务
$ ./zkServer.sh start
JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Starting zookeeper ... STARTED

启动后可以使用下面的命令查看服务状态
$ ./zkServer.sh status
JMX enabled by default
Using config: /opt/zookeeper/bin/../conf/zoo.cfg
Mode: standalone

5. 在Zookeeper服务器启动以后，就可以使用Zookeeper的客户端来连接并测试了。
$ ./zkCli.sh
或 
$ ./zkCli.sh -server 127.0.0.1:2181

连接之后可以时候help来查看有哪些命令可以使用

[zk: 127.0.0.1:2181(CONNECTED) 0] ls /							#查看根节点
[zookeeper]

[zk: 127.0.0.1:2181(CONNECTED) 1] create /mykey1 myvalue1 		#创建一个新节点mykey1
Created /mykey1
[zk: 127.0.0.1:2181(CONNECTED) 2] create /mykey2 myvalue2 		#创建一个新节点mykey2
Created /mykey2

[zk: 127.0.0.1:2181(CONNECTED) 13] ls /							#查看根节点
[mykey1, mykey2, zookeeper]

[zk: 127.0.0.1:2181(CONNECTED) 23] get /mykey1					#获取mykey1节点
myvalue1
cZxid = 0x6
ctime = Sat Sep 20 21:00:17 CST 2014
mZxid = 0x8
mtime = Sat Sep 20 21:01:06 CST 2014
pZxid = 0x6
cversion = 0
dataVersion = 1
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 9
numChildren = 0

[zk: 127.0.0.1:2181(CONNECTED) 23] get /mykey2					#获取mykey2节点
myvalue2
cZxid = 0x6
ctime = Sat Sep 20 21:00:17 CST 2014
mZxid = 0x8
mtime = Sat Sep 20 21:01:06 CST 2014
pZxid = 0x6
cversion = 0
dataVersion = 1
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 9
numChildren = 0


[zk: 127.0.0.1:2181(CONNECTED) 24] set /mykey1 myvalue11		#获取mykey1节点
[zk: 127.0.0.1:2181(CONNECTED) 25] set /mykey2 myvalue22		#获取mykey2节点

[zk: 127.0.0.1:2181(CONNECTED) 26] set /mykey1 					#删除mykey1节点
[zk: 127.0.0.1:2181(CONNECTED) 27] set /mykey2					#删除mykey2节点

================================================================================
Zookeeper实战之单机集群模式

前一篇文章介绍了Zookeeper的单机模式的安装及应用，但是Zookeeper是为了解决分布式应用场景的，所以通常都会运行在集群模式下。今天由于手头机器不足，所以今天打算在一台机器上部署三个Zookeeper服务来组成一个Zookeeper集群。这里解压Zookeeper的安装包到/opt目录下，这里用三个目录来代表三个Zookeeper实例，分别是/opt/zookeeper1，/opt/zookeeper2和/opt/zookeeper3.

1. 首先编辑每个Zookeeper目录下的conf/zoo.cfg文件。三个配置配置文件的内容分别如下

$ cat /opt/zookeeper1/conf/zoo.cfg
tickTime=2000
dataDir=/opt/zookeeper1/data
clientPort=2181
initLimit=10
syncLimit=5
server.1=127.0.0.1:2881:3881
server.2=127.0.0.1:2882:3882
server.3=127.0.0.1:2883:3883

$ cat /opt/zookeeper2/conf/zoo.cfg
tickTime=2000
dataDir=/opt/zookeeper2/data
clientPort=2182
initLimit=10
syncLimit=5
server.1=127.0.0.1:2881:3881
server.2=127.0.0.1:2882:3882
server.3=127.0.0.1:2883:3883

$ cat /opt/zookeeper3/conf/zoo.cfg
tickTime=2000
dataDir=/opt/zookeeper3/data
clientPort=2183
initLimit=10
syncLimit=5
server.1=127.0.0.1:2881:3881
server.2=127.0.0.1:2882:3882
server.3=127.0.0.1:2883:3883

其中有几点需要注意
* dataDir: 三个Zookeeper实例的dataDir目录要区别开，这里分别指定到各个Zookeeper实例目录下的data目录。
* clientPort: 定义Zookeeper客户端连接Zookeeper服务端时使用的端口，这里因为是在一台机器上做的集群，所以三个实例的端口要区分开。
* server.<id>: 定义Zookeeper集群的各个实例的的ip和端口，这里因为是在一台机器上做的集群，所以IP都定义的是127.0.0.1，但是后面的端口要区分开。

2. 创建data目录和实例id文件
mkdir /opt/zookeeper1/data
mkdir /opt/zookeeper2/data
mkdir /opt/zookeeper3/data
echo 1 > /opt/zookeeper1/data/myid
echo 2 > /opt/zookeeper2/data/myid
echo 3 > /opt/zookeeper3/data/myid
这里要注意需要在每个Zookeeper的dataDir目录下创建myid文件，内容是记录各个Zookeeper的实例ID。

3. 启动Zookeeper服务
分别进入各个Zookeeper的bin目录，然后运行“./zkServer.sh start”来启动一个Zookeeper服务。 

4. 客户端连接
随便进入一个Zookeeper的bin目录，然后运行
./zkCli.sh -server 127.0.0.1:2181
./zkCli.sh -server 127.0.0.1:2182
./zkCli.sh -server 127.0.0.1:2183
来分别连接Zookeeper服务。

在其中的一个client上创建一个znode节点
create /mykey myvalue

然后在别的client上查看新创建zonde节点
get /mykey

5. 查看Zookeeper状态
启动Zookeeper之后，由于Zookeeper自己会有一套leader的选举算法，所以此时如果想知道那个Zookeeper是leader可以在各个Zookeeper的bin目录运行“./zkServer.sh status”命令来查看。

如果是Leader
$ ./zkServer.sh status
JMX enabled by default
Using config: /opt/zookeeper1/bin/../conf/zoo.cfg
Mode: leader

如果不是Leader
$ ./zkServer.sh status
JMX enabled by default
Using config: /opt/zookeeper3/bin/../conf/zoo.cfg
Mode: follower

此时可以把leader的那个阶段停了，然后再看查看其它两个Zookeeper实例，此时剩下的两个Zookeeper实例就会再选举出一个leader。
